{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bhav_multiple_regression_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bs3537/DS-Unit-2-Linear-Models/blob/master/Bhav_multiple_regression_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx7fAxX8SpBU",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 2*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "# Regression 2\n",
        "\n",
        "## Assignment\n",
        "\n",
        "You'll continue to **predict how much it costs to rent an apartment in NYC,** using the dataset from renthop.com.\n",
        "\n",
        "- [ ] Do train/test split. Use data from April & May 2016 to train. Use data from June 2016 to test.\n",
        "- [ ] Engineer at least two new features. (See below for explanation & ideas.)\n",
        "- [ ] Fit a linear regression model with at least two features.\n",
        "- [ ] Get the model's coefficients and intercept.\n",
        "- [ ] Get regression metrics RMSE, MAE, and $R^2$, for both the train and test data.\n",
        "- [ ] What's the best test MAE you can get? Share your score and features used with your cohort on Slack!\n",
        "- [ ] As always, commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "\n",
        "#### [Feature Engineering](https://en.wikipedia.org/wiki/Feature_engineering)\n",
        "\n",
        "> \"Some machine learning projects succeed and some fail. What makes the difference? Easily the most important factor is the features used.\" — Pedro Domingos, [\"A Few Useful Things to Know about Machine Learning\"](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)\n",
        "\n",
        "> \"Coming up with features is difficult, time-consuming, requires expert knowledge. 'Applied machine learning' is basically feature engineering.\" — Andrew Ng, [Machine Learning and AI via Brain simulations](https://forum.stanford.edu/events/2011/2011slides/plenary/2011plenaryNg.pdf) \n",
        "\n",
        "> Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. \n",
        "\n",
        "#### Feature Ideas\n",
        "- Does the apartment have a description?\n",
        "- How long is the description?\n",
        "- How many total perks does each apartment have?\n",
        "- Are cats _or_ dogs allowed?\n",
        "- Are cats _and_ dogs allowed?\n",
        "- Total number of rooms (beds + baths)\n",
        "- Ratio of beds to baths\n",
        "- What's the neighborhood, based on address or latitude & longitude?\n",
        "\n",
        "## Stretch Goals\n",
        "- [ ] If you want more math, skim [_An Introduction to Statistical Learning_](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf),  Chapter 3.1, Simple Linear Regression, & Chapter 3.2, Multiple Linear Regression\n",
        "- [ ] If you want more introduction, watch [Brandon Foltz, Statistics 101: Simple Linear Regression](https://www.youtube.com/watch?v=ZkjP5RJLQF4)\n",
        "(20 minutes, over 1 million views)\n",
        "- [ ] Add your own stretch goal(s) !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9eSnDYhUGD7",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'\n",
        "    \n",
        "# Ignore this Numpy warning when using Plotly Express:\n",
        "# FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=FutureWarning, module='numpy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cvrw-T3bZOuW",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Read New York City apartment rental listing data\n",
        "df = pd.read_csv(DATA_PATH+'apartments/renthop-nyc.csv')\n",
        "assert df.shape == (49352, 34)\n",
        "\n",
        "# Remove the most extreme 1% prices,\n",
        "# the most extreme .1% latitudes, &\n",
        "# the most extreme .1% longitudes\n",
        "df = df[(df['price'] >= np.percentile(df['price'], 0.5)) & \n",
        "        (df['price'] <= np.percentile(df['price'], 99.5)) & \n",
        "        (df['latitude'] >= np.percentile(df['latitude'], 0.05)) & \n",
        "        (df['latitude'] < np.percentile(df['latitude'], 99.95)) &\n",
        "        (df['longitude'] >= np.percentile(df['longitude'], 0.05)) & \n",
        "        (df['longitude'] <= np.percentile(df['longitude'], 99.95))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPml-ia8Wkw2",
        "colab_type": "code",
        "outputId": "c9385d2d-b259-4061-941a-2c4a149ad2dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>created</th>\n",
              "      <th>description</th>\n",
              "      <th>display_address</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>price</th>\n",
              "      <th>street_address</th>\n",
              "      <th>interest_level</th>\n",
              "      <th>elevator</th>\n",
              "      <th>cats_allowed</th>\n",
              "      <th>hardwood_floors</th>\n",
              "      <th>dogs_allowed</th>\n",
              "      <th>doorman</th>\n",
              "      <th>dishwasher</th>\n",
              "      <th>no_fee</th>\n",
              "      <th>laundry_in_building</th>\n",
              "      <th>fitness_center</th>\n",
              "      <th>pre-war</th>\n",
              "      <th>laundry_in_unit</th>\n",
              "      <th>roof_deck</th>\n",
              "      <th>outdoor_space</th>\n",
              "      <th>dining_room</th>\n",
              "      <th>high_speed_internet</th>\n",
              "      <th>balcony</th>\n",
              "      <th>swimming_pool</th>\n",
              "      <th>new_construction</th>\n",
              "      <th>terrace</th>\n",
              "      <th>exclusive</th>\n",
              "      <th>loft</th>\n",
              "      <th>garden_patio</th>\n",
              "      <th>wheelchair_access</th>\n",
              "      <th>common_outdoor_space</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.5</td>\n",
              "      <td>3</td>\n",
              "      <td>2016-06-24 07:54:24</td>\n",
              "      <td>A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy ...</td>\n",
              "      <td>Metropolitan Avenue</td>\n",
              "      <td>40.7145</td>\n",
              "      <td>-73.9425</td>\n",
              "      <td>3000</td>\n",
              "      <td>792 Metropolitan Avenue</td>\n",
              "      <td>medium</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2016-06-12 12:19:27</td>\n",
              "      <td></td>\n",
              "      <td>Columbus Avenue</td>\n",
              "      <td>40.7947</td>\n",
              "      <td>-73.9667</td>\n",
              "      <td>5465</td>\n",
              "      <td>808 Columbus Avenue</td>\n",
              "      <td>low</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2016-04-17 03:26:41</td>\n",
              "      <td>Top Top West Village location, beautiful Pre-w...</td>\n",
              "      <td>W 13 Street</td>\n",
              "      <td>40.7388</td>\n",
              "      <td>-74.0018</td>\n",
              "      <td>2850</td>\n",
              "      <td>241 W 13 Street</td>\n",
              "      <td>high</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2016-04-18 02:22:02</td>\n",
              "      <td>Building Amenities - Garage - Garden - fitness...</td>\n",
              "      <td>East 49th Street</td>\n",
              "      <td>40.7539</td>\n",
              "      <td>-73.9677</td>\n",
              "      <td>3275</td>\n",
              "      <td>333 East 49th Street</td>\n",
              "      <td>low</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2016-04-28 01:32:41</td>\n",
              "      <td>Beautifully renovated 3 bedroom flex 4 bedroom...</td>\n",
              "      <td>West 143rd Street</td>\n",
              "      <td>40.8241</td>\n",
              "      <td>-73.9493</td>\n",
              "      <td>3350</td>\n",
              "      <td>500 West 143rd Street</td>\n",
              "      <td>low</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bathrooms  bedrooms  ... wheelchair_access common_outdoor_space\n",
              "0        1.5         3  ...                 0                    0\n",
              "1        1.0         2  ...                 0                    0\n",
              "2        1.0         1  ...                 0                    0\n",
              "3        1.0         1  ...                 0                    0\n",
              "4        1.0         4  ...                 0                    0\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXtB9J_3W8np",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let us exclude non-numeric columns from dataset\n",
        "df2 = df.select_dtypes(include='number')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJEs7JasXI_m",
        "colab_type": "code",
        "outputId": "0fa3cc96-f4c2-4595-bfa7-2722da622d2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>price</th>\n",
              "      <th>elevator</th>\n",
              "      <th>cats_allowed</th>\n",
              "      <th>hardwood_floors</th>\n",
              "      <th>dogs_allowed</th>\n",
              "      <th>doorman</th>\n",
              "      <th>dishwasher</th>\n",
              "      <th>no_fee</th>\n",
              "      <th>laundry_in_building</th>\n",
              "      <th>fitness_center</th>\n",
              "      <th>pre-war</th>\n",
              "      <th>laundry_in_unit</th>\n",
              "      <th>roof_deck</th>\n",
              "      <th>outdoor_space</th>\n",
              "      <th>dining_room</th>\n",
              "      <th>high_speed_internet</th>\n",
              "      <th>balcony</th>\n",
              "      <th>swimming_pool</th>\n",
              "      <th>new_construction</th>\n",
              "      <th>terrace</th>\n",
              "      <th>exclusive</th>\n",
              "      <th>loft</th>\n",
              "      <th>garden_patio</th>\n",
              "      <th>wheelchair_access</th>\n",
              "      <th>common_outdoor_space</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.5</td>\n",
              "      <td>3</td>\n",
              "      <td>40.7145</td>\n",
              "      <td>-73.9425</td>\n",
              "      <td>3000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>40.7947</td>\n",
              "      <td>-73.9667</td>\n",
              "      <td>5465</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>40.7388</td>\n",
              "      <td>-74.0018</td>\n",
              "      <td>2850</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>40.7539</td>\n",
              "      <td>-73.9677</td>\n",
              "      <td>3275</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>40.8241</td>\n",
              "      <td>-73.9493</td>\n",
              "      <td>3350</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bathrooms  bedrooms  ...  wheelchair_access  common_outdoor_space\n",
              "0        1.5         3  ...                  0                     0\n",
              "1        1.0         2  ...                  0                     0\n",
              "2        1.0         1  ...                  0                     0\n",
              "3        1.0         1  ...                  0                     0\n",
              "4        1.0         4  ...                  0                     0\n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdlciyMrXM3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert negative number to absolute numbers\n",
        "df3 = df2.abs()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm0--kmLXWAP",
        "colab_type": "code",
        "outputId": "270bb719-b49b-4da8-9031-b02f42cd1730",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "df3.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>price</th>\n",
              "      <th>elevator</th>\n",
              "      <th>cats_allowed</th>\n",
              "      <th>hardwood_floors</th>\n",
              "      <th>dogs_allowed</th>\n",
              "      <th>doorman</th>\n",
              "      <th>dishwasher</th>\n",
              "      <th>no_fee</th>\n",
              "      <th>laundry_in_building</th>\n",
              "      <th>fitness_center</th>\n",
              "      <th>pre-war</th>\n",
              "      <th>laundry_in_unit</th>\n",
              "      <th>roof_deck</th>\n",
              "      <th>outdoor_space</th>\n",
              "      <th>dining_room</th>\n",
              "      <th>high_speed_internet</th>\n",
              "      <th>balcony</th>\n",
              "      <th>swimming_pool</th>\n",
              "      <th>new_construction</th>\n",
              "      <th>terrace</th>\n",
              "      <th>exclusive</th>\n",
              "      <th>loft</th>\n",
              "      <th>garden_patio</th>\n",
              "      <th>wheelchair_access</th>\n",
              "      <th>common_outdoor_space</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>40.7145</td>\n",
              "      <td>73.9425</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>40.7947</td>\n",
              "      <td>73.9667</td>\n",
              "      <td>5465.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>40.7388</td>\n",
              "      <td>74.0018</td>\n",
              "      <td>2850.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>40.7539</td>\n",
              "      <td>73.9677</td>\n",
              "      <td>3275.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>40.8241</td>\n",
              "      <td>73.9493</td>\n",
              "      <td>3350.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bathrooms  bedrooms  ...  wheelchair_access  common_outdoor_space\n",
              "0        1.5       3.0  ...                0.0                   0.0\n",
              "1        1.0       2.0  ...                0.0                   0.0\n",
              "2        1.0       1.0  ...                0.0                   0.0\n",
              "3        1.0       1.0  ...                0.0                   0.0\n",
              "4        1.0       4.0  ...                0.0                   0.0\n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9W6Tf5OXZjT",
        "colab_type": "code",
        "outputId": "f82a1c22-9d02-4827-a457-f5aaf95b28dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        }
      },
      "source": [
        "#find null values\n",
        "df3.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bathrooms               0\n",
              "bedrooms                0\n",
              "latitude                0\n",
              "longitude               0\n",
              "price                   0\n",
              "elevator                0\n",
              "cats_allowed            0\n",
              "hardwood_floors         0\n",
              "dogs_allowed            0\n",
              "doorman                 0\n",
              "dishwasher              0\n",
              "no_fee                  0\n",
              "laundry_in_building     0\n",
              "fitness_center          0\n",
              "pre-war                 0\n",
              "laundry_in_unit         0\n",
              "roof_deck               0\n",
              "outdoor_space           0\n",
              "dining_room             0\n",
              "high_speed_internet     0\n",
              "balcony                 0\n",
              "swimming_pool           0\n",
              "new_construction        0\n",
              "terrace                 0\n",
              "exclusive               0\n",
              "loft                    0\n",
              "garden_patio            0\n",
              "wheelchair_access       0\n",
              "common_outdoor_space    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3KVO0TZjNCt",
        "colab_type": "code",
        "outputId": "2b9926ea-7b9f-4247-c5fd-aa4467f0b624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df3.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48817, 29)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeUNg1pKeF0k",
        "colab_type": "text"
      },
      "source": [
        "Split dataset into train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTZfFQkSeFHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC2xO--Ai_5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create training and test datasets\n",
        "# create training and testing vars\n",
        "train, test = train_test_split(df3, test_size=0.2, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P9eljsNlOSy",
        "colab_type": "code",
        "outputId": "f6b758f4-3e9a-43c9-b21c-f9bbb6ea1283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39053, 29)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mow5oQ1glU-2",
        "colab_type": "code",
        "outputId": "cc13df03-e293-4f50-9fbc-572168e6dc65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9764, 29)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KmluRmyvSdW",
        "colab_type": "text"
      },
      "source": [
        "Begin with baselines,, zero features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt44PCthvYUX",
        "colab_type": "code",
        "outputId": "253d65c6-cada-48be-8ae6-73e3715ccd12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train['price'].mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3578.6967710547206"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xexo9MrFvhok",
        "colab_type": "code",
        "outputId": "7f651599-66fe-45a3-aa38-6c218d185c1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Arrange y target vectors\n",
        "target = 'price'\n",
        "y_train = train[target]\n",
        "y_test = test[target]\n",
        "\n",
        "# Get mean baseline\n",
        "print('Mean Baseline (using 0 features)')\n",
        "guess = y_train.mean()\n",
        "\n",
        "# Train Error\n",
        "y_pred = [guess] * len(y_train)\n",
        "mae = mean_absolute_error(y_train, y_pred)\n",
        "print(f'Train Error (NYC rent): {mae:.2f} USD')\n",
        "\n",
        "# Test Error\n",
        "y_pred = [guess] * len(y_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f'Test Error (NYC rent): {mae:.2f} USD')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Baseline (using 0 features)\n",
            "Train Error (NYC rent): 1199.02 USD\n",
            "Test Error (NYC rent): 1210.35 USD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovmMBE7YxRte",
        "colab_type": "text"
      },
      "source": [
        "Exploring relationship of price with one variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oldozg0jxLpr",
        "colab_type": "code",
        "outputId": "480b2299-7e50-4c64-c9cb-0d150b97fb92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.lmplot(data=X_train, x=\"price\", y=\"longitude\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f0fe3c27e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFgCAYAAABqo8hyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kj9YmtUy8qo",
        "colab_type": "text"
      },
      "source": [
        "Linear regression with a single variable "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGMSn3rHy7li",
        "colab_type": "code",
        "outputId": "819372fc-506d-43ad-d956-d4226ba6a2b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# 1. Import the appropriate estimator class from Scikit-Learn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 2. Instantiate this class\n",
        "model = LinearRegression()\n",
        "\n",
        "# 3. Arrange X features matrices (already did y target vectors)\n",
        "features = ['longitude']\n",
        "X_train = train[features]\n",
        "X_test = test[features]\n",
        "print(f'Linear Regression, dependent on: {features}')\n",
        "\n",
        "# 4. Fit the model\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_train)\n",
        "mae = mean_absolute_error(y_train, y_pred)\n",
        "print(f'Train Error: {mae:.2f} USD')\n",
        "\n",
        "# 5. Apply the model to new data\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f'Test Error: {mae:.2f} USD')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear Regression, dependent on: ['longitude']\n",
            "Train Error: 1141.55 USD\n",
            "Test Error: 1153.83 USD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L-dXCplzXAy",
        "colab_type": "text"
      },
      "source": [
        "####Thus, both train error and test error are lower after including a single variable, longitude which appears to have a linear relationship with price on the seaborn plot.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfz-UHEizwc9",
        "colab_type": "text"
      },
      "source": [
        "Now, let us do linear regression including two variables, longitude and latitude"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6magQkur0ebE",
        "colab_type": "code",
        "outputId": "7d048644-4151-4f1f-9872-bb4124627db9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# Re-arrange X features matrices\n",
        "features = ['longitude', \n",
        "            'latitude']\n",
        "print(f'Linear Regression, dependent on: {features}')\n",
        "X_train = train[features]\n",
        "X_test = test[features]\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_pred_train = model.predict(X_train_scaled)\n",
        "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
        "print(f'Train error: {mae_train:.2f} USD')\n",
        "\n",
        "# Apply the model to new data\n",
        "y_pred_test = model.predict(X_test_scaled)\n",
        "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
        "print(f'Test error: {mae_test:.2f} USD')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear Regression, dependent on: ['longitude', 'latitude']\n",
            "Train error: 1143.85 USD\n",
            "Test error: 1155.20 USD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvwRxYSb0xP4",
        "colab_type": "text"
      },
      "source": [
        "By including latitude, our train and test errors are higher than just univariate linear regression with longitude, so latitude is not a good feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOHTbwyV1Eip",
        "colab_type": "text"
      },
      "source": [
        "Let us try including some other features like bedrooms, bathrooms, pets allowed or not, terrace etc. since these are theoretically expected to have a relationship with rent. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D_NbEYU1Atm",
        "colab_type": "code",
        "outputId": "50b0c972-2a1b-4e70-8100-bd98df6ae25a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# Re-arrange X features matrices\n",
        "features = ['bathrooms', \n",
        "            'bedrooms',\n",
        "            'longitude',\n",
        "            'latitude',\n",
        "            'terrace',\n",
        "            'swimming_pool',\n",
        "            'dogs_allowed',\n",
        "            'cats_allowed',\n",
        "            'elevator',\n",
        "            'fitness_center',\n",
        "            'pre-war',\n",
        "            'laundry_in_unit',\n",
        "            'roof_deck',\n",
        "            'high_speed_internet',\n",
        "            'doorman',\n",
        "            'loft',\n",
        "            'garden_patio',\n",
        "            'no_fee']\n",
        "print(f'Linear Regression, dependent on: {features}')\n",
        "X_train = train[features]\n",
        "X_test = test[features]\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_pred_train = model.predict(X_train_scaled)\n",
        "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
        "print(f'Train error: {mae_train:.2f} USD')\n",
        "\n",
        "# Apply the model to new data\n",
        "y_pred_test = model.predict(X_test_scaled)\n",
        "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
        "print(f'Test error: {mae_test:.2f} USD')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear Regression, dependent on: ['bathrooms', 'bedrooms', 'longitude', 'latitude', 'terrace', 'swimming_pool', 'dogs_allowed', 'cats_allowed', 'elevator', 'fitness_center', 'pre-war', 'laundry_in_unit', 'roof_deck', 'high_speed_internet', 'doorman', 'loft', 'garden_patio', 'no_fee']\n",
            "Train error: 700.97 USD\n",
            "Test error: 703.18 USD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDe1J9xB4FxN",
        "colab_type": "text"
      },
      "source": [
        "Thus, our multivariate regression model was able to significantly reduce the train and test errors from zero feature and single feature by including multiple features which are expected to have a relationship with the apartment rent. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjlPns2C40MJ",
        "colab_type": "text"
      },
      "source": [
        "Get the model's coefficients and intercept."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwVQVFXI414m",
        "colab_type": "code",
        "outputId": "2d4f99d2-4ae0-4066-87a5-cdbaa7f4e856",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Model Intercept\", model.intercept_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Intercept 3578.6967710546814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yOcj0Zh5cUO",
        "colab_type": "code",
        "outputId": "df2c4afb-2d54-4ba6-a242-1864db9fb628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(\"Model Coefficients\", model.coef_)\n",
        "#The output has multiple coefficients since we included 18 features in our linear regression model."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Coefficients [852.14279879 529.05705244 387.55568763  66.52495951  21.24624212\n",
            "  16.81817964  77.04867757 -33.89605173  49.43010647  51.05463895\n",
            " -13.98904173 163.48425463 -53.24357465 -92.79853782 246.90129258\n",
            "  24.14842841   8.84573754 -98.46589881]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvnoKMXI8kGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Features in the model = \n",
        "#numerical variables = number of bathrooms, number of bedrooms, longitude, latitude\n",
        "#categorical variables (1=yes, 0 =no): terrace, swimming pool, dog allowed, cats allowed, elevator, \n",
        "#                                      fitness center, pre-war, laundry in the unit, roof deck, high speed internet, \n",
        "#                                      doorman, loft, garden patio, no fee. \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfIth5E78fZb",
        "colab_type": "code",
        "outputId": "49cb9b29-22a0-4c11-dd3f-97182018f10b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Testing the model #with terrace and swimming pool and fitness center, 2 bedrooms and 1 bathroom\n",
        "model.predict([[1, 2, 73.9425, 40.7145, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([37456.56729824])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RmuUPhI_pME",
        "colab_type": "code",
        "outputId": "a1e36567-8e27-400f-bfa4-33b6378d3d2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Testing the model #with terrace and swimming pool and fitness center, 3 bedrooms and 2 bathrooms\n",
        "model.predict([[2, 3, 73.9425, 40.7145, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([38837.76714946])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjaqXR65-9RE",
        "colab_type": "code",
        "outputId": "a90c9cda-19a1-4ab2-e47a-ef0ca6e44bc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Testing the model with 1 bedroom, 1 bathroom and no swimming pool, terrace or fitness center and not pre-war and different location by longitude and latitude.\n",
        "model.predict([[1, 1, 73.9667, 40.7947, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([36620.19308363])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WelOkb9733u",
        "colab_type": "text"
      },
      "source": [
        "Get regression metrics RMSE, MAE, and  R2 , for both the train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqJKDHHwJghX",
        "colab_type": "code",
        "outputId": "e7658d2b-923f-4be8-cbb5-add69a040ff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "#Train data\n",
        "import statsmodels.api as sm # import statsmodels \n",
        "\n",
        "X = X_train_scaled ## X usually means our input variables (or independent variables)\n",
        "y = y_train ## Y usually means our output/dependent variable\n",
        "X = sm.add_constant(X) ## let's add an intercept (beta_0) to our model\n",
        "\n",
        "# Note the difference in argument order\n",
        "model = sm.OLS(y, X).fit() ## sm.OLS(output, input)\n",
        "predictions = model.predict(X)\n",
        "\n",
        "# Print out the statistics\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.612</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.612</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   3419.</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 02 Nov 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>03:29:12</td>     <th>  Log-Likelihood:    </th> <td>-3.2876e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td> 39053</td>      <th>  AIC:               </th>  <td>6.576e+05</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td> 39034</td>      <th>  BIC:               </th>  <td>6.577e+05</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>    18</td>      <th>                     </th>      <td> </td>     \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td> 3578.6968</td> <td>    5.547</td> <td>  645.215</td> <td> 0.000</td> <td> 3567.825</td> <td> 3589.568</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>    <td>  852.1428</td> <td>    6.766</td> <td>  125.941</td> <td> 0.000</td> <td>  838.881</td> <td>  865.405</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>    <td>  529.0571</td> <td>    6.759</td> <td>   78.277</td> <td> 0.000</td> <td>  515.810</td> <td>  542.305</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th>    <td>  387.5557</td> <td>    6.179</td> <td>   62.725</td> <td> 0.000</td> <td>  375.445</td> <td>  399.666</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th>    <td>   66.5250</td> <td>    5.923</td> <td>   11.232</td> <td> 0.000</td> <td>   54.916</td> <td>   78.133</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th>    <td>   21.2462</td> <td>    6.203</td> <td>    3.425</td> <td> 0.001</td> <td>    9.088</td> <td>   33.405</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x6</th>    <td>   16.8182</td> <td>    6.051</td> <td>    2.780</td> <td> 0.005</td> <td>    4.959</td> <td>   28.677</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x7</th>    <td>   77.0487</td> <td>   15.944</td> <td>    4.833</td> <td> 0.000</td> <td>   45.799</td> <td>  108.299</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x8</th>    <td>  -33.8961</td> <td>   15.924</td> <td>   -2.129</td> <td> 0.033</td> <td>  -65.107</td> <td>   -2.686</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x9</th>    <td>   49.4301</td> <td>    7.200</td> <td>    6.866</td> <td> 0.000</td> <td>   35.318</td> <td>   63.542</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x10</th>   <td>   51.0546</td> <td>    7.755</td> <td>    6.584</td> <td> 0.000</td> <td>   35.855</td> <td>   66.254</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x11</th>   <td>  -13.9890</td> <td>    5.623</td> <td>   -2.488</td> <td> 0.013</td> <td>  -25.011</td> <td>   -2.967</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x12</th>   <td>  163.4843</td> <td>    6.053</td> <td>   27.011</td> <td> 0.000</td> <td>  151.621</td> <td>  175.347</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x13</th>   <td>  -53.2436</td> <td>    7.007</td> <td>   -7.598</td> <td> 0.000</td> <td>  -66.978</td> <td>  -39.509</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x14</th>   <td>  -92.7985</td> <td>    6.653</td> <td>  -13.949</td> <td> 0.000</td> <td> -105.838</td> <td>  -79.759</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x15</th>   <td>  246.9013</td> <td>    8.178</td> <td>   30.190</td> <td> 0.000</td> <td>  230.872</td> <td>  262.931</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x16</th>   <td>   24.1484</td> <td>    5.664</td> <td>    4.263</td> <td> 0.000</td> <td>   13.047</td> <td>   35.250</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x17</th>   <td>    8.8457</td> <td>    6.134</td> <td>    1.442</td> <td> 0.149</td> <td>   -3.178</td> <td>   20.870</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x18</th>   <td>  -98.4659</td> <td>    6.171</td> <td>  -15.956</td> <td> 0.000</td> <td> -110.562</td> <td>  -86.370</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>21547.040</td> <th>  Durbin-Watson:     </th>  <td>   2.006</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>427297.082</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>           <td> 2.237</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>       <td>18.575</td>   <th>  Cond. No.          </th>  <td>    7.49</td> \n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                  price   R-squared:                       0.612\n",
              "Model:                            OLS   Adj. R-squared:                  0.612\n",
              "Method:                 Least Squares   F-statistic:                     3419.\n",
              "Date:                Sat, 02 Nov 2019   Prob (F-statistic):               0.00\n",
              "Time:                        03:29:12   Log-Likelihood:            -3.2876e+05\n",
              "No. Observations:               39053   AIC:                         6.576e+05\n",
              "Df Residuals:                   39034   BIC:                         6.577e+05\n",
              "Df Model:                          18                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const       3578.6968      5.547    645.215      0.000    3567.825    3589.568\n",
              "x1           852.1428      6.766    125.941      0.000     838.881     865.405\n",
              "x2           529.0571      6.759     78.277      0.000     515.810     542.305\n",
              "x3           387.5557      6.179     62.725      0.000     375.445     399.666\n",
              "x4            66.5250      5.923     11.232      0.000      54.916      78.133\n",
              "x5            21.2462      6.203      3.425      0.001       9.088      33.405\n",
              "x6            16.8182      6.051      2.780      0.005       4.959      28.677\n",
              "x7            77.0487     15.944      4.833      0.000      45.799     108.299\n",
              "x8           -33.8961     15.924     -2.129      0.033     -65.107      -2.686\n",
              "x9            49.4301      7.200      6.866      0.000      35.318      63.542\n",
              "x10           51.0546      7.755      6.584      0.000      35.855      66.254\n",
              "x11          -13.9890      5.623     -2.488      0.013     -25.011      -2.967\n",
              "x12          163.4843      6.053     27.011      0.000     151.621     175.347\n",
              "x13          -53.2436      7.007     -7.598      0.000     -66.978     -39.509\n",
              "x14          -92.7985      6.653    -13.949      0.000    -105.838     -79.759\n",
              "x15          246.9013      8.178     30.190      0.000     230.872     262.931\n",
              "x16           24.1484      5.664      4.263      0.000      13.047      35.250\n",
              "x17            8.8457      6.134      1.442      0.149      -3.178      20.870\n",
              "x18          -98.4659      6.171    -15.956      0.000    -110.562     -86.370\n",
              "==============================================================================\n",
              "Omnibus:                    21547.040   Durbin-Watson:                   2.006\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           427297.082\n",
              "Skew:                           2.237   Prob(JB):                         0.00\n",
              "Kurtosis:                      18.575   Cond. No.                         7.49\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ctk-D2txaBF_",
        "colab_type": "text"
      },
      "source": [
        "The output above gives R2 = 0.612, so 61.2% of the variance in rent price is explained by our multivariate linear regression model.\n",
        "The output summary for the model also gives us the constant 3578.69 which is the model intercept.\n",
        "The output summary for the model also gives us all the 18 coefficients for the 18 different variables that we selected. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzK6jy13K9Wk",
        "colab_type": "code",
        "outputId": "c353be85-772d-4cc6-af7c-8f16afeb1740",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "#Model summary for test dataset\n",
        "X1 = X_test_scaled ## X usually means our input variables (or independent variables)\n",
        "y1 = y_pred_test ## Y usually means our output/dependent variable\n",
        "X1 = sm.add_constant(X1) ## let's add an intercept (beta_0) to our model\n",
        "\n",
        "# Note the difference in argument order\n",
        "model = sm.OLS(y1, X1).fit() ## sm.OLS(output, input)\n",
        "predictions = model.predict(X1)\n",
        "\n",
        "# Print out the statistics\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>2.451e+31</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 02 Nov 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>03:49:09</td>     <th>  Log-Likelihood:    </th> <td>2.3756e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>  9764</td>      <th>  AIC:               </th> <td>-4.751e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>  9745</td>      <th>  BIC:               </th> <td>-4.749e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>    18</td>      <th>                     </th>      <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td> 3578.6968</td> <td> 6.66e-14</td> <td> 5.37e+16</td> <td> 0.000</td> <td> 3578.697</td> <td> 3578.697</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>    <td>  852.1428</td> <td> 8.07e-14</td> <td> 1.06e+16</td> <td> 0.000</td> <td>  852.143</td> <td>  852.143</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>    <td>  529.0571</td> <td> 8.16e-14</td> <td> 6.49e+15</td> <td> 0.000</td> <td>  529.057</td> <td>  529.057</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th>    <td>  387.5557</td> <td> 7.51e-14</td> <td> 5.16e+15</td> <td> 0.000</td> <td>  387.556</td> <td>  387.556</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th>    <td>   66.5250</td> <td> 6.99e-14</td> <td> 9.52e+14</td> <td> 0.000</td> <td>   66.525</td> <td>   66.525</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th>    <td>   21.2462</td> <td> 7.62e-14</td> <td> 2.79e+14</td> <td> 0.000</td> <td>   21.246</td> <td>   21.246</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x6</th>    <td>   16.8182</td> <td>  7.1e-14</td> <td> 2.37e+14</td> <td> 0.000</td> <td>   16.818</td> <td>   16.818</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x7</th>    <td>   77.0487</td> <td> 1.92e-13</td> <td> 4.01e+14</td> <td> 0.000</td> <td>   77.049</td> <td>   77.049</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x8</th>    <td>  -33.8961</td> <td> 1.92e-13</td> <td>-1.76e+14</td> <td> 0.000</td> <td>  -33.896</td> <td>  -33.896</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x9</th>    <td>   49.4301</td> <td> 8.61e-14</td> <td> 5.74e+14</td> <td> 0.000</td> <td>   49.430</td> <td>   49.430</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x10</th>   <td>   51.0546</td> <td> 9.23e-14</td> <td> 5.53e+14</td> <td> 0.000</td> <td>   51.055</td> <td>   51.055</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x11</th>   <td>  -13.9890</td> <td> 6.65e-14</td> <td> -2.1e+14</td> <td> 0.000</td> <td>  -13.989</td> <td>  -13.989</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x12</th>   <td>  163.4843</td> <td> 7.16e-14</td> <td> 2.28e+15</td> <td> 0.000</td> <td>  163.484</td> <td>  163.484</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x13</th>   <td>  -53.2436</td> <td> 8.48e-14</td> <td>-6.28e+14</td> <td> 0.000</td> <td>  -53.244</td> <td>  -53.244</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x14</th>   <td>  -92.7985</td> <td>  7.9e-14</td> <td>-1.17e+15</td> <td> 0.000</td> <td>  -92.799</td> <td>  -92.799</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x15</th>   <td>  246.9013</td> <td> 9.92e-14</td> <td> 2.49e+15</td> <td> 0.000</td> <td>  246.901</td> <td>  246.901</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x16</th>   <td>   24.1484</td> <td> 6.99e-14</td> <td> 3.45e+14</td> <td> 0.000</td> <td>   24.148</td> <td>   24.148</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x17</th>   <td>    8.8457</td> <td> 7.74e-14</td> <td> 1.14e+14</td> <td> 0.000</td> <td>    8.846</td> <td>    8.846</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x18</th>   <td>  -98.4659</td> <td> 7.39e-14</td> <td>-1.33e+15</td> <td> 0.000</td> <td>  -98.466</td> <td>  -98.466</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>1649.636</td> <th>  Durbin-Watson:     </th> <td>   1.275</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2780.997</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>           <td> 1.119</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>       <td> 4.353</td>  <th>  Cond. No.          </th> <td>    7.60</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   R-squared:                       1.000\n",
              "Model:                            OLS   Adj. R-squared:                  1.000\n",
              "Method:                 Least Squares   F-statistic:                 2.451e+31\n",
              "Date:                Sat, 02 Nov 2019   Prob (F-statistic):               0.00\n",
              "Time:                        03:49:09   Log-Likelihood:             2.3756e+05\n",
              "No. Observations:                9764   AIC:                        -4.751e+05\n",
              "Df Residuals:                    9745   BIC:                        -4.749e+05\n",
              "Df Model:                          18                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const       3578.6968   6.66e-14   5.37e+16      0.000    3578.697    3578.697\n",
              "x1           852.1428   8.07e-14   1.06e+16      0.000     852.143     852.143\n",
              "x2           529.0571   8.16e-14   6.49e+15      0.000     529.057     529.057\n",
              "x3           387.5557   7.51e-14   5.16e+15      0.000     387.556     387.556\n",
              "x4            66.5250   6.99e-14   9.52e+14      0.000      66.525      66.525\n",
              "x5            21.2462   7.62e-14   2.79e+14      0.000      21.246      21.246\n",
              "x6            16.8182    7.1e-14   2.37e+14      0.000      16.818      16.818\n",
              "x7            77.0487   1.92e-13   4.01e+14      0.000      77.049      77.049\n",
              "x8           -33.8961   1.92e-13  -1.76e+14      0.000     -33.896     -33.896\n",
              "x9            49.4301   8.61e-14   5.74e+14      0.000      49.430      49.430\n",
              "x10           51.0546   9.23e-14   5.53e+14      0.000      51.055      51.055\n",
              "x11          -13.9890   6.65e-14   -2.1e+14      0.000     -13.989     -13.989\n",
              "x12          163.4843   7.16e-14   2.28e+15      0.000     163.484     163.484\n",
              "x13          -53.2436   8.48e-14  -6.28e+14      0.000     -53.244     -53.244\n",
              "x14          -92.7985    7.9e-14  -1.17e+15      0.000     -92.799     -92.799\n",
              "x15          246.9013   9.92e-14   2.49e+15      0.000     246.901     246.901\n",
              "x16           24.1484   6.99e-14   3.45e+14      0.000      24.148      24.148\n",
              "x17            8.8457   7.74e-14   1.14e+14      0.000       8.846       8.846\n",
              "x18          -98.4659   7.39e-14  -1.33e+15      0.000     -98.466     -98.466\n",
              "==============================================================================\n",
              "Omnibus:                     1649.636   Durbin-Watson:                   1.275\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2780.997\n",
              "Skew:                           1.119   Prob(JB):                         0.00\n",
              "Kurtosis:                       4.353   Cond. No.                         7.60\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBO34h90RPgH",
        "colab_type": "text"
      },
      "source": [
        "####R2 for the test dataset is 1, so 100% of the variance in rent in test dataset is explained by our multivariate regression model. Thus, our multivariate linear regression has 100% predictive accuracy in predicting rent in the test dataset. That is a good result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwRRJ3lBTCNO",
        "colab_type": "text"
      },
      "source": [
        "In machine learning, the test data accuracy is more important, so my multiple regression model has 100% predictive accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6M2kawrYxtA",
        "colab_type": "text"
      },
      "source": [
        "I also played around with some other variables but was unable to get R2 of higher than 61.2% in train dataset. I would prefer >70% for train dataset but for this dataset, I can't get higher R2 in train data."
      ]
    }
  ]
}